{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1 (Bernouilli)\n",
    "\n",
    "Let $y$ be a random variable that is drawn from a Bernouilli distribution with probability of success $p$. \n",
    "\n",
    "1. Consider a dataset $Y=(y_1,y_2,...,y_n)$ containing $n$ realizations of $y$. Write down the likelihood of $Y$ as a function of $p$.\n",
    "\n",
    "2. Assume that $p$ itself is drawn from the following distribution\n",
    "\\begin{equation*}\n",
    "p=\\left\\{ \n",
    "\\begin{array}{l}\n",
    "p_{h}\\text{ with probability} \\mu _{0}, \\\\ \n",
    "p_{l}\\text{ with probability} 1-\\mu _{0}.%\n",
    "\\end{array}%\n",
    "\\right. \n",
    "\\end{equation*}%\n",
    "The variable $\\mu_0$ denotes the prior in period $0$. Use Bayes rule to express the agent’s posterior $μ_1(0)$ at the beginning of period $2$ after having observed a failure in period $1$, i.e. $y_1=0$. Iterate the computation to derive the posterior after $n$ failures in a row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "1. The likelihood of $Y$ can be written as\n",
    "\n",
    "\\begin{equation*}\n",
    "    L\\left(p | Y \\right) = \\prod_{i = 1}^{n} p^{y_{i}}(1-p)^{1-y_{i}}\n",
    "\\end{equation*}\n",
    "\n",
    "2. By the Baye's rule, we can express $μ_1(0)$ as:\n",
    "\n",
    "\\begin{align*}\n",
    "    μ_1(0) = p(p_{h}|y_{1}=0) & = \\frac{p(y_{1}=0|p_{h})\\mu_{0}}{p(y_{1}=0|p_{h})\\mu_{0} + p(y_{1}=0|p_{l})(1-\\mu_{0})}\\\\\n",
    "                              & = \\frac{(1-p_{h})\\mu_{0}}{(1-p_{h})\\mu_{0} + (1-p_{l})(1-\\mu_{0})}.\n",
    "\\end{align*}\n",
    "\n",
    "The posterior after $n$ failures could be expressed as:\n",
    "\n",
    "\\begin{align*}\n",
    "    μ_n(0) = p(p_{h}|y_{1}=0, y_{2}=0,...,y_{n}=0) & = \\frac{p(y_{1}=0, y_{2}=0,...,y_{n}=0|p_{h})\\mu_{0}}{p(y_{1}=0, y_{2}=0,...,y_{n}=0|p_{h})\\mu_{0} + p(y_{1}=0, y_{2}=0,...,y_{n}=0|p_{l})(1-\\mu_{0})}\\\\\n",
    "                              & = \\frac{(1-p_{h})^{n}\\mu_{0}}{(1-p_{h})^{n}\\mu_{0} + (1-p_{l})^{n}(1-\\mu_{0})}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2 (Normal-Normal conjugacy)\n",
    "\n",
    "Let $y$ be a random variable that is drawn from a normal distribution with mean $\\mu$ and standard deviation $\\sigma$. \n",
    "\n",
    "1. Consider a dataset $Y=(y_1,y_2,...,y_n)$ containing $n$ realizations of $y$. Write down the likelihood of $Y$ as a function of $\\mu$ and  $\\sigma$\n",
    "\n",
    "2. Assume that $\\mu$ itself is Normally distributed around some mean $\\theta$ with standard deviation $\\tau$. Show that upon observing $Y$, the posterior belief about $\\mu$ remains normally distributed. Derive the posterior mean and standard deviation of $\\mu$. What do you notice about the standard deviation? Comment your finding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "1. The likelihood of $Y$ can be written as\n",
    "\n",
    "\\begin{align*}\n",
    "    L\\left(\\mu, \\sigma | Y \\right) &= \\prod_{i = 1}^{n} f\\left(y_{i}|\\mu, \\sigma\\right) \\\\\n",
    "                                   &= \\prod_{i = 1}^{n} \\frac{1}{\\sqrt{2\\pi \\sigma^{2}}}\\text{exp}\\left(-\\frac{\\left(y_{i}-\\mu\\right)^{2}}{2\\sigma^{2}}\\right).\n",
    "\\end{align*}\n",
    "\n",
    "2. By the Bayes' rule, we find the posterior distribution of $\\mu$ given the data $Y$:\n",
    "\n",
    "\\begin{align*}\n",
    "     p\\left(\\mu|Y,\\theta,\\tau,\\sigma\\right) &\\propto p\\left(Y|\\mu,\\sigma\\right)p\\left(\\mu|\\theta,\\tau\\right)\\\\\n",
    "        & \\propto \\text{exp}\\left(-\\frac{1}{2}[\\frac{1}{\\sigma^{2}}\\sum_{i=1}^{n}\\left(y_{i}-\\mu\\right)^{2} + \\frac{\\left(\\mu-\\theta\\right)^{2}}{\\tau^{2}}]\\right).\n",
    "\\end{align*}\n",
    "\n",
    "Let $\\overline{y} = \\frac{1}{n}\\sum_{i=1}^{n}y_{i}$, by the Law of Total Variance, we have \n",
    "\n",
    "\\begin{equation*}\n",
    "    \\sum_{i=1}^{n}\\left(y_{i}-\\mu\\right)^{2} = \\sum_{i=1}^{n}\\left(y_{i} - \\overline{y}\\right)^{2} + n\\left(\\overline{y}-\\mu\\right)^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "Thus the posterior is simplified to:\n",
    "\n",
    "\\begin{equation*}\n",
    "    p\\left(\\mu|Y,\\theta,\\tau,\\sigma\\right) \\propto \\text{exp}\\left(-\\frac{1}{2}[\\frac{n\\left(\\overline{y}-\\mu\\right)^{2}}{\\sigma^{2}} + \\frac{\\left(\\mu-\\theta\\right)^{2}}{\\tau^2}]\\right).\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "The exponent can be written as:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\left(\\mu - \\frac{\\frac{\\overline{y}}{\\sigma^{2}} + \\frac{\\theta}{\\tau^{2}}}{\\frac{n}{\\sigma^{2}} + \\frac{1}{\\tau^{2}}}\\right)^{2}\\left(\\frac{n}{\\sigma^{2}} + \\frac{1}{\\tau^{2}}\\right).\n",
    "\\end{equation*}\n",
    "\n",
    "From this, we can find the posterior mean $\\mu_{post}$ and the posterior variance $\\sigma^{2}_{post}$ to be:\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\mu_{post} = \\frac{\\frac{\\overline{y}}{\\sigma^{2}} + \\frac{\\theta}{\\tau^{2}}}{\\frac{n}{\\sigma^{2}} + \\frac{1}{\\tau^{2}}} \\\\\n",
    "    & \\sigma^{2}_{post} = \\frac{1}{\\frac{n}{\\sigma^{2}} + \\frac{1}{\\tau^{2}}}.\n",
    "\\end{align*}\n",
    "\n",
    "Note that the posterior variance is smaller than either the prior variance or the variance of the sample mean, reflecting the fact that after observing the data, we have more information about $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.3 (Job Search)\n",
    "\n",
    "We consider a labor market where workers are either employed or searching\n",
    "for a job.\\ Time is discrete and agents discount the future at rate $r$, so\n",
    "that their discount factor $\\beta =1/(1+r).$ When a firm meets a job seeker,\n",
    "it offers her a constant wage contract and the firm-employee relationship \n",
    "**lasts forever**.\n",
    "\n",
    "At the **end** of each period:\n",
    "\n",
    "(i). Employed workers receive their wages.\n",
    "\n",
    "(ii). Unemployed workers receive their benefits $z=-1$ along with a job\n",
    "offer whose wage is sampled from the following distribution\n",
    "\\begin{equation*}\n",
    "w=\n",
    "p=\\left\\{ \n",
    "\\begin{array}{l}\n",
    "1\\text{\\ with\\ probability}\\ p, \\\\ \n",
    "0\\text{\\ with\\ probability}\\ 1-p.%\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\end{equation*}\n",
    "\n",
    "<br>\n",
    "\n",
    "1. Write down the Bellman equation for an unemployed worker and\n",
    "for a worker employed at wage $w$. Reinsert the value function $E(w)$ of\n",
    "employed workers into that of unemployed workers $U$ to express the latter\n",
    "as a function of $w$.\n",
    "\n",
    "2. Consider the following two job searching strategies. One\n",
    "where the worker accepts all job offers, which we denote by $U^{A}$; and one\n",
    "where the worker rejects low-wage offers ($w=0$), which we denote by $U^{R}.$\n",
    "Compute the values of $U^{A}$ and $U^{R}.$\n",
    "\n",
    "3. Under which condition on $p$ is it optimal for workers to\n",
    "reject low-wage offers? Provide an economic intuition for your result.\n",
    "(Hint: Remember that $z=-1.$)\n",
    "\n",
    "4. We now assume that the worker search for only two periods.\n",
    "What is the value function $U_{2}$ of an unemployed worker in the second\n",
    "and last search period?\n",
    " \n",
    "5. Consider now the value of being unemployed in the first\n",
    "search period $U_{1}$. Again, compare two job searching strategies: one\n",
    "where the worker accepts all job offers ($U_{1}^{A}$); and one where the\n",
    "worker rejects low-wage offers ($U_{1}^{R}$). Compute the two value\n",
    "functions.\n",
    "\n",
    "6. Under which condition is it optimal to reject low-wage offers\n",
    "in the first period? Compare your answer to the solution in 3. Provide\n",
    "an interpretation for your finding.\n",
    "\n",
    "7. We now assume that workers are uncertain about the probability \n",
    "$p$ at which they receive high-wage offers. Their initial belief at the\n",
    "beginning of period 1 is given by\n",
    "\\begin{equation*}\n",
    "p=\\left\\{ \n",
    "\\begin{array}{l}\n",
    "p_{h}\\text{ with probability} \\mu _{1}, \\\\ \n",
    "p_{l}\\text{ with probability} 1-\\mu _{1},\n",
    "\\end{array}\n",
    "\\right. \n",
    "\\end{equation*}\n",
    "where $p_{h}>p_{l}.$ Use Bayes rule to express the agent's posterior $\\mu\n",
    "_{2}(0)$ at the beginning of period $2$ after she has received a low\n",
    "wage-offer. Show that $\\mu _{2}(0)<\\mu _{1}.$ In particular, what is the value of $\\mu_{2}(0)$ when $p_{h}=1?$\n",
    "\n",
    "8. We assume that $p_{h}=1$. Compute $U_{1}^{R}$ and $U_{1}^{A}$\n",
    "under Bayesian learning. Under which condition is it optimal to reject a\n",
    "low-wage offer in period 1?\n",
    "\n",
    "9. Compare your answer to the solution in 6. What is the\n",
    "impact of learning on the search strategy? Provide an economic intuition\n",
    "for your result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "1. The Bellman equation for an unemployed worker can be written as:\n",
    "\n",
    "\\begin{equation*}\n",
    "    U = \\frac{1}{1+r}(z + \\text{max}\\{U, E(\\overline{w})\\}p + \\text{max}\\{U, E(\\underline{w})\\}(1-p)),\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\overline{w} = 1$ and $\\underline{w} = 0$. The vqlue function $E(w) = \\frac{w}{r}$. Inserting into $U$, we have:\n",
    "\n",
    "\\begin{equation*}\n",
    "    U = \\frac{1}{1+r}(z + \\text{max}\\{U, \\frac{\\overline{w}}{r}\\}p + \\text{max}\\{U, \\frac{\\underline{w}}{r}\\}(1-p)).\n",
    "\\end{equation*}\n",
    "\n",
    "2. The job searching srategies could be expressed as:\n",
    "\n",
    "\\begin{align*}\n",
    "    & U^A = \\frac{1}{1+r}(z + p\\frac{\\overline{w}}{r} + (1-p)\\frac{\\underline{w}}{r}) = \\frac{p-r}{(1+r)r}\\\\\n",
    "    & U^R = \\frac{1}{1+r}(z + p\\frac{\\overline{w}}{r} + (1-p)U^R) \\rightarrow U^R = \\frac{p-r}{(p +r)r}\n",
    "\\end{align*}\n",
    "\n",
    "3. For $U^R > U^A$, we will require that $r<p<1$. Since remaining unemployed will incur a loss, the probability of receiving an offer of higher wages must be high enough to compensate for staying unemployed.\n",
    "\n",
    "4. In the second period, if the worker rejects the offer, she will stay unempolyed forever ane receive $\\frac{z}{r}<\\frac{w}{r}$. Therefore, all workers will accept the offer in the second period. Then $U_2 = U_R$ as of Question 2. Therfore, we have $U_2 = \\frac{p-r}{(p +r)r}$.\n",
    "\n",
    "5. $U_1^A$ and $U_1^R$ can be expressed as:\n",
    "\n",
    "\\begin{align*}\n",
    "    &  U_1^A = \\frac{p-r}{(1+r)r}\\\\\n",
    "    &  U_1^R = \\frac{1}{1+r}(z + \\frac{p}{r} + (1-p)U_2) = U_1^A + \\frac{1-p}{1+r}U_2.\n",
    "\\end{align*}\n",
    "\n",
    "6. For $U_1^R$ to be greater than $U_1^A$, we only need to have $U_2>0$, which requires $p>r$. This is the same as the solution in 3. (a bit confusing?)\n",
    "\n",
    "7. By Baye's rule, $\\mu _{2}(0)$ can be expressed as:\n",
    "\n",
    "\\begin{align*}\n",
    "     \\mu _{2}(0) &= p(p_h| w_1=0)\\\\\n",
    "                 &= \\frac{p(w_1=0|p_h)p(p_h)}{p(w_1=0|p_h)p(p_h)+p(w_1=0|p_l)p(p_l)}\\\\\n",
    "                 &= \\frac{(1-p_h)\\mu_1}{(1-p_h)\\mu_1+(1-p_l)(1-\\mu_1)}.\n",
    "\\end{align*}\n",
    "\n",
    "Comparing the value of $\\mu _{2}(0)$ and $\\mu _{1}$, since $p_h>p_l$ we have:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\mu _{2}(0) - \\mu _{1} = \\frac{(1-p_h)(1-\\mu _{1})-(1-p_l)(1-\\mu _{0})}{(1-p_h)\\mu_1+(1-p_l)(1-\\mu_1)}<0.\n",
    "\\end{equation*}\n",
    "\n",
    "When $p_h=1$, we have $ \\mu _{2}(0) = 0$.\n",
    "\n",
    "8. With $p_h=1$, $ U_1^A$ and $U_1^R$ can be expressed as:\n",
    "\n",
    "\\begin{align*}\n",
    "    &U_1^A = \\frac{1}{1+r}(z + \\frac{\\mu_1}{r} + (1-\\mu_1)\\frac{p_l}{r})\\\\\n",
    "    &U_1^R = \\frac{1}{1+r}(z + \\frac{\\mu_1}{r} + (1-\\mu_1)U_2)\n",
    "\\end{align*}\n",
    "\n",
    "where, by Baye's rule, $U_2 = \\frac{1}{1+r}(z + \\frac{\\mu_2}{r} + (1-\\mu_2)\\frac{p_l}{r})$. Since when $p_h=1$, we have $\\mu_2=0$. Therefore, $U_1^R = \\frac{1}{1+r}(z + \\frac{\\mu_1}{r}) + \\frac{1-\\mu_1}{(1+r)^2}(z+\\frac{p_l}{r})$.\n",
    "\n",
    "Note that for $U_1^R > U_1^A$, we will require that $z>p_l$, which is impossible. Therefore, the agent will always accept the offer in the first period.\n",
    "\n",
    "9. In 6, the agent will reject the offer if the probability of obtaining a high-wage offer is large enough. However, with the given prior belief, the agent will always accept the offer as she believes that there will not be high-wage offer apprearing if a low-wage offer is obtained in the first period."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
